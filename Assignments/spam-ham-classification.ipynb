{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'sms'], dtype='object')\n",
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 256\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sms.tsv\", sep='\\t')\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of classes: 2\n",
      "['ham', 'spam']\n",
      "{'ham': 0, 'spam': 1}\n"
     ]
    }
   ],
   "source": [
    "classes = sorted(set(df['label']))\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "nclass = len(classes)\n",
    "\n",
    "print(\"# of classes: %d\" % nclass)\n",
    "print(classes)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n",
      "5169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>So lets make it saturday or monday as per conv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol u still feeling sick?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Looks like u wil b getting a headstart im leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Which channel:-):-):):-).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>We don call like  &amp;lt;#&amp;gt;  times oh. No give...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  So lets make it saturday or monday as per conv...\n",
       "1   ham                          Lol u still feeling sick?\n",
       "2   ham  Looks like u wil b getting a headstart im leav...\n",
       "3   ham                          Which channel:-):-):):-).\n",
       "4   ham  We don call like  &lt;#&gt;  times oh. No give..."
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({\"label\": df[\"label\"], \"sms\": df[\"sms\"].str.slice(start=0, stop=max_length)})\n",
    "\n",
    "print(len(new_df))\n",
    "new_df = pd.DataFrame(new_df.drop_duplicates())\n",
    "\n",
    "print(len(new_df))\n",
    "\n",
    "df_shuffled = new_df.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index for train: 0~4652\n",
      "index for test: 4652 ~ 5168\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.9\n",
    "\n",
    "s, e = 0, int(df_shuffled.shape[0] * train_ratio)\n",
    "df_train = pd.DataFrame({\"label\": df_shuffled[\"label\"][s:e], \"sms\":df_shuffled[\"sms\"][s:e]})\n",
    "print(\"index for train: %d~%d\" % (s, e))\n",
    "\n",
    "s, e = e, e + int(df_shuffled.shape[0] * (1.0 - train_ratio))\n",
    "print(\"index for test: %d ~ %d\" % (s, e))\n",
    "df_test = pd.DataFrame({\"label\": df_shuffled[\"label\"][s:e], \"sms\":df_shuffled[\"sms\"][s:e]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4652, 2)\n",
      "(516, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"./sms.maxlen.uniq.shuf.train.tsv\", header=False, index=False, sep='\\t')\n",
    "df_test.to_csv(\"./sms.maxlen.uniq.shuf.test.tsv\", header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext==0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.4.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.14.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (2.22.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (1.18.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchtext==0.4.0) (4.42.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (1.25.10)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0) (2.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.3 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p36/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import numpy as np\n",
    "from data_loader import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "word_vec_size = 256\n",
    "dropout_p = 0.3\n",
    "\n",
    "hidden_size = 512\n",
    "num_layers = 4\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = DataLoader(train_fn='./sms.maxlen.uniq.shuf.train.tsv', \n",
    "                    batch_size=batch_size,\n",
    "                    valid_ratio=.2,\n",
    "                    device=-1,\n",
    "                    max_vocab=999999,\n",
    "                    min_freq=5,\n",
    "                    )\n",
    "\n",
    "test_loader = DataLoader(train_fn='./sms.maxlen.uniq.shuf.test.tsv', \n",
    "                    batch_size=batch_size,\n",
    "                    valid_ratio=.01,\n",
    "                    device=-1,\n",
    "                    max_vocab=999999,\n",
    "                    min_freq=5,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|train| = 3722 |valid| = 930\n",
      "|vocab| = 1563 |classes| = 2\n"
     ]
    }
   ],
   "source": [
    "print(\"|train| =\", len(loaders.train_loader.dataset),\n",
    "     \"|valid| =\", len(loaders.valid_loader.dataset))\n",
    "\n",
    "vocab_size = len(loaders.text.vocab)\n",
    "num_classes = len(loaders.label.vocab)\n",
    "print(\"|vocab| =\", vocab_size, \"|classes| =\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "한 번에 로드되는 데이터 크기: 128\n",
      "label: 1\n",
      "text: (35,)\n",
      "label: 0\n",
      "text: (35,)\n",
      "label: 0\n",
      "text: (35,)\n",
      "[1]\n",
      "한 번에 로드되는 데이터 크기: 128\n",
      "label: 0\n",
      "text: (9,)\n",
      "label: 0\n",
      "text: (9,)\n",
      "label: 0\n",
      "text: (9,)\n",
      "[2]\n",
      "한 번에 로드되는 데이터 크기: 128\n",
      "label: 0\n",
      "text: (7,)\n",
      "label: 0\n",
      "text: (7,)\n",
      "label: 0\n",
      "text: (7,)\n",
      "[3]\n",
      "한 번에 로드되는 데이터 크기: 128\n",
      "label: 0\n",
      "text: (18,)\n",
      "label: 0\n",
      "text: (18,)\n",
      "label: 0\n",
      "text: (18,)\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "for i, data in enumerate(loaders.train_loader):\n",
    "    labels = data.label\n",
    "    texts = data.text\n",
    "    \n",
    "    if i > n:\n",
    "        break\n",
    "    \n",
    "    print(\"[%d]\" %i)\n",
    "    print(\"한 번에 로드되는 데이터 크기:\", len(labels))\n",
    "    \n",
    "    for j in range(n):\n",
    "        label = labels[j].numpy()\n",
    "        text = texts[j].numpy()\n",
    "        print(\"label:\", label)\n",
    "        print(\"text:\", text.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,  input_size, word_vec_size, hidden_size, n_classes, num_layers=4, dropout_p=0.3):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        self.emb = nn.Embedding(input_size, word_vec_size)\n",
    "        self.lstm = nn.LSTM(input_size=word_vec_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           num_layers=num_layers,\n",
    "                           dropout=dropout_p,\n",
    "                           batch_first=True,\n",
    "                           bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        \n",
    "        self.activation = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        out = self.activation(self.fc(x[:, -1]))\n",
    "        \n",
    "        return out\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=vocab_size,\n",
    "            word_vec_size=word_vec_size,\n",
    "            hidden_size=hidden_size,\n",
    "            n_classes=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            dropout_p=dropout_p\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccr(dloader, imodel):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i, data in enumerate(dloader):\n",
    "        texts = data.text.to(device)\n",
    "        labels = data.label.to(device)\n",
    "        output = model(texts)\n",
    "        _, output_index = torch.max(output, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (output_index == labels).sum().float()\n",
    "    \n",
    "    model.train()\n",
    "    return (100 * correct / total).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 11.29\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" % ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [1/10], Step [10/30], Loss: 0.0141, Accr: 96.67\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [1/10], Step [20/30], Loss: 0.0005, Accr: 96.67\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [1/10], Step [30/30], Loss: 0.0005, Accr: 96.56\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [2/10], Step [10/30], Loss: 0.0003, Accr: 96.45\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [2/10], Step [20/30], Loss: 0.0010, Accr: 96.67\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [2/10], Step [30/30], Loss: 0.0069, Accr: 96.77\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [3/10], Step [10/30], Loss: 0.0008, Accr: 96.77\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [3/10], Step [20/30], Loss: 0.0000, Accr: 96.67\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [3/10], Step [30/30], Loss: 0.0006, Accr: 96.67\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [4/10], Step [10/30], Loss: 0.0010, Accr: 96.77\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [4/10], Step [20/30], Loss: 0.0011, Accr: 96.99\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [4/10], Step [30/30], Loss: 0.0009, Accr: 96.99\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [5/10], Step [10/30], Loss: 0.0000, Accr: 97.20\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [5/10], Step [20/30], Loss: 0.0002, Accr: 96.88\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [5/10], Step [30/30], Loss: 0.0001, Accr: 96.45\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [6/10], Step [10/30], Loss: 0.0034, Accr: 96.77\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [6/10], Step [20/30], Loss: 0.0006, Accr: 96.77\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [6/10], Step [30/30], Loss: 0.0000, Accr: 96.99\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [7/10], Step [10/30], Loss: 0.0010, Accr: 96.02\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [7/10], Step [20/30], Loss: 0.0009, Accr: 96.45\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [7/10], Step [30/30], Loss: 0.0000, Accr: 96.67\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [8/10], Step [10/30], Loss: 0.0002, Accr: 96.67\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [8/10], Step [20/30], Loss: 0.0012, Accr: 96.56\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [8/10], Step [30/30], Loss: 0.0001, Accr: 96.67\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [9/10], Step [10/30], Loss: 0.0000, Accr: 96.45\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [9/10], Step [20/30], Loss: 0.0006, Accr: 96.45\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [9/10], Step [30/30], Loss: 0.0001, Accr: 96.56\n",
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n",
      "[6]\n",
      "[7]\n",
      "[8]\n",
      "[9]\n",
      "Epoch [10/10], Step [10/30], Loss: 0.0000, Accr: 96.56\n",
      "[10]\n",
      "[11]\n",
      "[12]\n",
      "[13]\n",
      "[14]\n",
      "[15]\n",
      "[16]\n",
      "[17]\n",
      "[18]\n",
      "[19]\n",
      "Epoch [10/10], Step [20/30], Loss: 0.0001, Accr: 96.67\n",
      "[20]\n",
      "[21]\n",
      "[22]\n",
      "[23]\n",
      "[24]\n",
      "[25]\n",
      "[26]\n",
      "[27]\n",
      "[28]\n",
      "[29]\n",
      "Epoch [10/10], Step [30/30], Loss: 0.0000, Accr: 96.77\n"
     ]
    }
   ],
   "source": [
    "total_step = len(loaders.train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(loaders.train_loader):\n",
    "        texts = data.text.to(device)\n",
    "        labels = data.label.to(device)\n",
    "        \n",
    "        print(\"[%d]\" % i)\n",
    "        \n",
    "        outputs = model(texts)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print(\"Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accr: {:.2f}\"\n",
    "                  .format(epoch+1, num_epochs, i+1, total_step,\n",
    "                         loss.item(),\n",
    "                         ComputeAccr(loaders.valid_loader, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Valid Date: 96.77\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Valid Date: %.2f\" % ComputeAccr(loaders.valid_loader, model))\n",
    "netname = \"./rnn_weight.pkl\"\n",
    "torch.save(model, netname)\n",
    "\n",
    "model = torch.load(netname)\n",
    "\n",
    "print(\"Accuracy of Valid Date: %.2f\" % ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
